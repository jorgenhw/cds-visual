{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 6 - Benchmark classification on ```cifar-10```\n",
    "\n",
    "This notebook builds on what we were doing last week with the handwritten digits from the MNIST dataset.\n",
    "\n",
    "This week, we're working with another famous dataset in computer vision and image processing research - [cifar10](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 11:20:10.683302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# path tools\n",
    "import os\n",
    "\n",
    "# data loader\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# machine learning tools\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# classificatio models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7343d4b5",
   "metadata": {},
   "source": [
    "We're going to load the data using a function from the library ```TensorFlow```, which we'll be looking at in more detail next week. \n",
    "\n",
    "For now, we're just using it to fetch the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 14s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() # cifar10 has function to load data.\n",
    "# here cifar are returning both training and testing data, grouped by X and y."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b588be73",
   "metadata": {},
   "source": [
    "**Question:** What is the shape of the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c30422d",
   "metadata": {},
   "source": [
    "50000 refers to number of images, 32 and 32 is the dimensions of each image in pixels and 3 is color channels\n",
    "For the y_train the numbers refers to the labels attached to each image. 50000 tags in all."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd02fcbe",
   "metadata": {},
   "source": [
    "Unfortunately, this version of the data set doesn't have explict labels (there are just number 0-8), so we need to create our own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = [\"airplane\", \n",
    "          \"automobile\", \n",
    "          \"bird\", \n",
    "          \"cat\", \n",
    "          \"deer\", \n",
    "          \"dog\", \n",
    "          \"frog\", \n",
    "          \"horse\", \n",
    "          \"ship\", \n",
    "          \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87c513e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to convert labels to uppercase\n",
    "#uppers = [labels.upper() for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all the data to greyscale"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f5391f3",
   "metadata": {},
   "source": [
    "In the following cell, I'm converting all of my images to greyscale and then making a ```numpy``` array at the end.\n",
    "\n",
    "Notice that I'm using something funky here called *[list comprehensions](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions)*. the downside of list comprehensions are useful but does decrease readability of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "X_train_grey = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train]) # convert each image in X_train to grey scale using list comprehension\n",
    "X_test_grey = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72c32a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_grey.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9fa3529",
   "metadata": {},
   "source": [
    "Now that they are grey, we lose the color channels, and thus one dimension"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9703dbdc",
   "metadata": {},
   "source": [
    "Then, we're going to do some simple scaling by dividing by 255.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_scaled = (X_train_grey)/255.0\n",
    "X_test_scaled = (X_test_grey)/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c141a5e2",
   "metadata": {},
   "source": [
    "Next, we're going to reshape this data. \n",
    "\n",
    "We do this to make the data compatiable with the neural network. We flatten the data, to flatten the pixels into one dimension. \n",
    "\n",
    "However, reshape function is a bit different (see below comments). This approach is similar to flattening, just smarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_train_scaled.shape # returns (50000, 32, 32)\n",
    "X_train_dataset = X_train_scaled.reshape((nsamples,nx*ny)) # we want the new shape to be the number of values on the x axis, and the number of values on the y axis.\n",
    "# so we are reshaping the data to be 50000 rows, and 1024 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nsamples, nx, ny = X_test_scaled.shape\n",
    "X_test_dataset = X_test_scaled.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ec06b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1024)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple logistic regression classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15bdea84",
   "metadata": {},
   "source": [
    "We define our Logistic Regression classifier as we have done previously. You'll notice that I've set a lot of different parameters here - you can learn more in the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9f832fc",
   "metadata": {},
   "source": [
    "* tol: tolerance for stopping criteria: stop when the loss function is less than 0.1. Meaning that if the weights of the model is not improving by more than 0.1 according to the stop loss function, stop training. The function does not say after how many iterations the model is not improving\n",
    "\n",
    "* verbose: For the liblinear and lbfgs solvers set verbose to any positive number for verbosity.\n",
    "\n",
    "* solver: Algorithm to use in the optimization problem. It optimizes the loss function basically. \n",
    "\n",
    "* multi_class: Whether the data is multinomial or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Library/Python/3.8/lib/python/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/Users/wibe/Library/Python/3.8/lib/python/site-packages/sklearn/utils/validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, change: 1.00000000\n",
      "Epoch 2, change: 0.23390008\n",
      "Epoch 3, change: 0.12836014\n",
      "Epoch 4, change: 0.11127933\n",
      "convergence after 5 epochs took 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.3s finished\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(penalty=\"none\", # no regularization of the weights\n",
    "                        tol=0.1, # \n",
    "                        verbose=True, # \n",
    "                        solver=\"saga\", # stochastic average gradient descent\n",
    "                        multi_class=\"multinomial\").fit(X_train_dataset, y_train) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc10cdb4",
   "metadata": {},
   "source": [
    "We can then print our classification report, using the label names that we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.34      0.38      0.36      1000\n",
      "  automobile       0.36      0.38      0.37      1000\n",
      "        bird       0.27      0.21      0.24      1000\n",
      "         cat       0.21      0.18      0.19      1000\n",
      "        deer       0.25      0.20      0.22      1000\n",
      "         dog       0.31      0.29      0.30      1000\n",
      "        frog       0.28      0.32      0.30      1000\n",
      "       horse       0.31      0.33      0.32      1000\n",
      "        ship       0.33      0.42      0.37      1000\n",
      "       truck       0.41      0.43      0.42      1000\n",
      "\n",
      "    accuracy                           0.31     10000\n",
      "   macro avg       0.31      0.31      0.31     10000\n",
      "weighted avg       0.31      0.31      0.31     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, \n",
    "                               y_pred, \n",
    "                               target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network classifier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79f6d9b4",
   "metadata": {},
   "source": [
    "I've set a couple of different parameters here - you can see more in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
    "\n",
    "**NB!** This will take a long time to run! On the 32 CPU machine on UCloud, this takes around 30 seconds per iteration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ae1c24b",
   "metadata": {},
   "source": [
    "* adaptive learning rate: The learning adjusts its value according to how close it gets to global minimum. The lower the loss function, the lower the learning rate to get as close to the global minimum as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Library/Python/3.8/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1091: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.30872956\n",
      "Validation score: 0.133000\n",
      "Iteration 2, loss = 2.15971661\n",
      "Validation score: 0.239200\n",
      "Iteration 3, loss = 2.02581278\n",
      "Validation score: 0.265200\n",
      "Iteration 4, loss = 1.97076182\n",
      "Validation score: 0.281800\n",
      "Iteration 5, loss = 1.93555578\n",
      "Validation score: 0.302600\n",
      "Iteration 6, loss = 1.90926190\n",
      "Validation score: 0.315600\n",
      "Iteration 7, loss = 1.89160286\n",
      "Validation score: 0.318800\n",
      "Iteration 8, loss = 1.87500641\n",
      "Validation score: 0.322200\n",
      "Iteration 9, loss = 1.86730610\n",
      "Validation score: 0.316800\n",
      "Iteration 10, loss = 1.85845283\n",
      "Validation score: 0.321200\n",
      "Iteration 11, loss = 1.84549829\n",
      "Validation score: 0.331400\n",
      "Iteration 12, loss = 1.83590762\n",
      "Validation score: 0.328600\n",
      "Iteration 13, loss = 1.82908945\n",
      "Validation score: 0.331400\n",
      "Iteration 14, loss = 1.82320985\n",
      "Validation score: 0.330600\n",
      "Iteration 15, loss = 1.81056794\n",
      "Validation score: 0.343400\n",
      "Iteration 16, loss = 1.80707784\n",
      "Validation score: 0.338400\n",
      "Iteration 17, loss = 1.79877427\n",
      "Validation score: 0.339800\n",
      "Iteration 18, loss = 1.79244407\n",
      "Validation score: 0.351000\n",
      "Iteration 19, loss = 1.78417279\n",
      "Validation score: 0.348800\n",
      "Iteration 20, loss = 1.78163463\n",
      "Validation score: 0.363800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Library/Python/3.8/lib/python/site-packages/sklearn/neural_network/_multilayer_perceptron.py:679: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=42,\n",
    "                    hidden_layer_sizes=(64, 10), # 64 neurons in the first layer, 10 neurons in the second layer\n",
    "                    learning_rate=\"adaptive\", # adaptive learning rate:\n",
    "                    early_stopping=True, # set to true to stop training when the validation score stops improving for x consecutive epochs\n",
    "                    verbose=True,\n",
    "                    max_iter=20).fit(X_train_dataset, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d4d94bd",
   "metadata": {},
   "source": [
    "**Validation score:** When training a model, we learn loss values based on the validation data which is a small portion of the training data or a manually defined portion of the all data. The validation score is how well is performs on this validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e489977e",
   "metadata": {},
   "source": [
    "Lastly, we can get our classification report as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.38      0.41      0.40      1000\n",
      "  automobile       0.40      0.49      0.44      1000\n",
      "        bird       0.26      0.34      0.30      1000\n",
      "         cat       0.28      0.11      0.16      1000\n",
      "        deer       0.27      0.26      0.27      1000\n",
      "         dog       0.33      0.34      0.34      1000\n",
      "        frog       0.28      0.29      0.28      1000\n",
      "       horse       0.45      0.39      0.42      1000\n",
      "        ship       0.44      0.44      0.44      1000\n",
      "       truck       0.42      0.47      0.44      1000\n",
      "\n",
      "    accuracy                           0.35     10000\n",
      "   macro avg       0.35      0.35      0.35     10000\n",
      "weighted avg       0.35      0.35      0.35     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_test, \n",
    "                               y_pred, \n",
    "                               target_names=labels)\n",
    "print(report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a5067ab",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Take the code outlined in this notebook and turn it into two separate Python scripts, one which performs Logistic Regression classification and one which uses the MLPClassifier on the ```Cifar10``` dataset.\n",
    "\n",
    "Try to use the things we've spoken about in clas\n",
    "- Requirements.txt\n",
    "- Virtual environment\n",
    "- Setup scripts\n",
    "- Argparse\n",
    "\n",
    "This task is [Assignment 2 for Visual Analytics](https://classroom.github.com/a/KLVvny7d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77a87d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f648ceb0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
